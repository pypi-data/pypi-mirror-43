{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import math\n",
    "import time\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask import compute, delayed\n",
    "import dask.threaded\n",
    "import joblib\n",
    "\n",
    "from sklearn.utils.testing import assert_array_equal\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def read_data(file):\n",
    "    '''\n",
    "    adhoc function to read data\n",
    "    '''\n",
    "    data = file.readlines()\n",
    "    rows = [row.decode('utf-8').strip().split('  ') for row in data]\n",
    "    X = pd.DataFrame(rows, dtype=np.float)\n",
    "    y = X.pop(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, the classification labels are used as regression targets for testing\n",
    "url = 'http://www.timeseriesclassification.com/Downloads/GunPoint.zip'\n",
    "url = urlopen(url)\n",
    "zipfile = ZipFile(BytesIO(url.read()))\n",
    "\n",
    "train_file = zipfile.open('GunPoint_TRAIN.txt')\n",
    "X_train_pd, y_train_pd = read_data(train_file)\n",
    "\n",
    "test_file = zipfile.open('GunPoint_TEST.txt')\n",
    "X_test_pd, y_test_pd = read_data(test_file)\n",
    "Xsf_test = pd.Series([row for _, row in X_test_pd.iterrows()])\n",
    "Xdf_test = pd.DataFrame({'ts': Xsf_test, 'ts_copy': Xsf_test})\n",
    "\n",
    "y_train = pd.Series(np.array(y_train_pd, dtype=np.int))\n",
    "Xsf_train = pd.Series([row for _, row in X_train_pd.iterrows()])\n",
    "Xdf_train = pd.DataFrame({'ts': Xsf_train, 'ts_copy': Xsf_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsf_loong = pd.concat([Xsf_train for _ in range(200)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946 ms ± 18.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using pandas inbuilt function\n",
    "%timeit Xsf_loong.apply(np.mean)\n",
    "# I think we cannot use pandas groupby for inbuilt parallelism\n",
    "# as mutable types (our pd.Series elements in each cell) cannot be\n",
    "# hashed, which apparently is a requirement\n",
    "target = Xsf_loong.apply(np.mean)  # for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895 ms ± 24.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using np.apply_along_axis\n",
    "%timeit pd.Series(np.apply_along_axis(np.mean, 1, np.array(Xsf_loong.to_list())))\n",
    "# numpy is a little faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 s ± 28.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using explicit for loop\n",
    "function = lambda X: pd.DataFrame([np.mean(row) for row in X])\n",
    "%timeit function(Xsf_loong)\n",
    "# looks like pandas is currently using explicit for loop internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568 ms ± 73.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# using joblib for parallel processing after splitting the dataframe\n",
    "with joblib.Parallel(n_jobs=-1) as parallel:\n",
    "    function = lambda Z: pd.concat(parallel(joblib.delayed(lambda X: X.apply(np.mean))(part) for part in np.array_split(Z, 2)))\n",
    "    %timeit function(Xsf_loong)\n",
    "# dataframe was split into two and processed in parallel\n",
    "# the speed-up can easily be seen\n",
    "got = function(Xsf_loong)  # for comparison\n",
    "assert_array_equal(got, target)  # no difference in the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 s ± 46.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# attempt nesting parallel operations (performing the same thing 4 times)\n",
    "# using joblib for parallel processing after splitting the dataframe\n",
    "def par_func(dummy):\n",
    "    with joblib.Parallel(n_jobs=-1) as parallel:\n",
    "        function = lambda Z: pd.concat(parallel(joblib.delayed(lambda X: X.apply(np.mean))(part) for part in np.array_split(Z, 2)))\n",
    "        function(Xsf_loong)\n",
    "\n",
    "with joblib.Parallel(n_jobs=-1) as parallel:\n",
    "    %timeit parallel(joblib.delayed(par_func)(i) for i in range(4))\n",
    "# note that the time is for performing the previous cell operation 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717 µs ± 32.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# using Dask (a pandas replacement, with inherent parallel processing)\n",
    "# it basically splits the data frame for parallel processing\n",
    "# but is more well managed and scales to clusters\n",
    "# can also work with big huge datasets without loading everything\n",
    "# into the RAM\n",
    "Dsf_train = dd.from_pandas(Xsf_train, npartitions=3)\n",
    "# should specify output datatype of the function\n",
    "%timeit Dsf_train.apply(np.mean, meta=float)\n",
    "# This is byfar the easiest and quickest option\n",
    "# But, this is not a drop-in replacement for pandas\n",
    "# Please see dask-ml, which has a sklearn clone with dask compatibility\n",
    "# the time shown is only for graph making not actual computation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
